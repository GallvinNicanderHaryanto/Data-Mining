{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuFb1MP_O5EW",
    "outputId": "17a158d8-8df8-4af8-d8cb-b15b95e590c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDYkmRlZPSXY"
   },
   "source": [
    "# Association Rule for Store Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYfOAa9fPjln"
   },
   "source": [
    "In this case study, we will explore how association rule can be used to analyze the items that are usualy purcased together.\n",
    "\n",
    "you can refer to this article to find out about apriori and association rule:\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EOg6BIYPxt4"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp0OZCjrQT1n"
   },
   "source": [
    "We will use the dataset of the transaction in a certain store. You can get the dataset here: \n",
    "https://gist.githubusercontent.com/Harsh-Git-Hub/2979ec48043928ad9033d8469928e751/raw/72de943e040b8bd0d087624b154d41b2ba9d9b60/retail_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LDF65VBRQjFL",
    "outputId": "e9c6b17c-3450-4b26-af48-e963cc0dd11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1     2       3       4       5       6\n",
      "0   Bread    Wine  Eggs    Meat  Cheese  Pencil  Diaper\n",
      "1   Bread  Cheese  Meat  Diaper    Wine    Milk  Pencil\n",
      "2  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
      "3  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
      "4    Meat  Pencil  Wine     NaN     NaN     NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# load the data set and show the first five transaction\n",
    "\n",
    "url = \"https://gist.githubusercontent.com/Harsh-Git-Hub/2979ec48043928ad9033d8469928e751/raw/72de943e040b8bd0d087624b154d41b2ba9d9b60/retail_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkfhUabDQup9"
   },
   "source": [
    "# Get the set of product that has been purchased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the unique product that has been purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Awz6VzuMwR_-",
    "outputId": "1fc181b3-cffe-48fe-9d3b-066323061907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Diaper', 'Meat', 'Bread', 'Cheese', 'Eggs', 'Wine', 'Bagel', 'Milk', 'Pencil'}\n"
     ]
    }
   ],
   "source": [
    "unique_products = df[\"0\"].unique()\n",
    "print(set(unique_products))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4g4k83bP07H"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEnL1bXtRLXe"
   },
   "source": [
    "In this step, we will transform our dataset so that we will have a one hot encoding based on the purchased products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "N4wdVmFWQ_yg"
   },
   "outputs": [],
   "source": [
    "#create an itemset based on the products\n",
    "transactions = df.apply(lambda x: x.dropna().tolist(), axis=1)\n",
    "\n",
    "# encoding the feature\n",
    "te = TransactionEncoder()\n",
    "encoded_transactions = te.fit_transform(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "v67eBdxByEJX",
    "outputId": "b05c05fb-7ae1-4fbe-a01a-d6985c360f5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bagel</th>\n",
       "      <th>Bread</th>\n",
       "      <th>Cheese</th>\n",
       "      <th>Diaper</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Pencil</th>\n",
       "      <th>Wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bagel  Bread  Cheese  Diaper  Eggs  Meat  Milk  Pencil  Wine\n",
       "0      0      1       1       1     1     1     0       1     1\n",
       "1      0      1       1       1     0     1     1       1     1\n",
       "2      0      0       1       0     1     1     1       0     1\n",
       "3      0      0       1       0     1     1     1       0     1\n",
       "4      0      0       0       0     0     1     0       1     1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dataframe from the encoded features\n",
    "df_encoded = pd.DataFrame(encoded_transactions, columns=te.columns_)\n",
    "df_encoded = df_encoded.astype(int)\n",
    "\n",
    "# show the new dataframe\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBJmzWAAS4Mw"
   },
   "source": [
    "Since, the encoded dataframe consist of the empty column. We will drop the NaN column or select all columns other than the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "2eHZu15xyTqm",
    "outputId": "7bffff16-fc02-48fe-bc98-7616bf75908e"
   },
   "outputs": [],
   "source": [
    "df_encoded = df_encoded.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UXDzSNPP35P"
   },
   "source": [
    "## Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-jD3ea4TYMV"
   },
   "source": [
    "We will use appriori algorithm to determine the frequently purchased products. \n",
    "For this case study, we will min_support=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BLA4Jqhoyjof",
    "outputId": "bc435206-1be2-41e6-b05b-0f1ba125e955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "     support              itemsets\n",
      "0   0.425397               (Bagel)\n",
      "1   0.504762               (Bread)\n",
      "2   0.501587              (Cheese)\n",
      "3   0.406349              (Diaper)\n",
      "4   0.438095                (Eggs)\n",
      "5   0.476190                (Meat)\n",
      "6   0.501587                (Milk)\n",
      "7   0.361905              (Pencil)\n",
      "8   0.438095                (Wine)\n",
      "9   0.279365        (Bagel, Bread)\n",
      "10  0.225397         (Bagel, Milk)\n",
      "11  0.238095       (Cheese, Bread)\n",
      "12  0.231746       (Diaper, Bread)\n",
      "13  0.206349         (Meat, Bread)\n",
      "14  0.279365         (Milk, Bread)\n",
      "15  0.200000       (Pencil, Bread)\n",
      "16  0.244444         (Wine, Bread)\n",
      "17  0.200000      (Cheese, Diaper)\n",
      "18  0.298413        (Cheese, Eggs)\n",
      "19  0.323810        (Cheese, Meat)\n",
      "20  0.304762        (Cheese, Milk)\n",
      "21  0.200000      (Cheese, Pencil)\n",
      "22  0.269841        (Cheese, Wine)\n",
      "23  0.234921        (Diaper, Wine)\n",
      "24  0.266667          (Eggs, Meat)\n",
      "25  0.244444          (Eggs, Milk)\n",
      "26  0.241270          (Eggs, Wine)\n",
      "27  0.244444          (Meat, Milk)\n",
      "28  0.250794          (Meat, Wine)\n",
      "29  0.219048          (Wine, Milk)\n",
      "30  0.200000        (Pencil, Wine)\n",
      "31  0.215873  (Cheese, Eggs, Meat)\n",
      "32  0.203175  (Cheese, Meat, Milk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(df_encoded, min_support=0.2, use_colnames=True)\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEr2YXHrVOIA"
   },
   "source": [
    "Then, we will generate association rule of the frequent itemset based on confidence level with the threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "5GalSXOoy6H8",
    "outputId": "2fc5a421-bca1-41c8-f96a-e24f49280d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       antecedents consequents  antecedent support  consequent support  \\\n",
      "0          (Bagel)     (Bread)            0.425397            0.504762   \n",
      "1           (Eggs)    (Cheese)            0.438095            0.501587   \n",
      "2         (Cheese)      (Meat)            0.501587            0.476190   \n",
      "3           (Meat)    (Cheese)            0.476190            0.501587   \n",
      "4         (Cheese)      (Milk)            0.501587            0.501587   \n",
      "5           (Milk)    (Cheese)            0.501587            0.501587   \n",
      "6           (Wine)    (Cheese)            0.438095            0.501587   \n",
      "7           (Eggs)      (Meat)            0.438095            0.476190   \n",
      "8   (Cheese, Eggs)      (Meat)            0.298413            0.476190   \n",
      "9   (Cheese, Meat)      (Eggs)            0.323810            0.438095   \n",
      "10    (Eggs, Meat)    (Cheese)            0.266667            0.501587   \n",
      "11  (Cheese, Meat)      (Milk)            0.323810            0.501587   \n",
      "12  (Cheese, Milk)      (Meat)            0.304762            0.476190   \n",
      "13    (Meat, Milk)    (Cheese)            0.244444            0.501587   \n",
      "\n",
      "     support  confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0   0.279365    0.656716  1.301042  0.064641    1.442650       0.402687  \n",
      "1   0.298413    0.681159  1.358008  0.078670    1.563203       0.469167  \n",
      "2   0.323810    0.645570  1.355696  0.084958    1.477891       0.526414  \n",
      "3   0.323810    0.680000  1.355696  0.084958    1.557540       0.500891  \n",
      "4   0.304762    0.607595  1.211344  0.053172    1.270148       0.350053  \n",
      "5   0.304762    0.607595  1.211344  0.053172    1.270148       0.350053  \n",
      "6   0.269841    0.615942  1.227986  0.050098    1.297754       0.330409  \n",
      "7   0.266667    0.608696  1.278261  0.058050    1.338624       0.387409  \n",
      "8   0.215873    0.723404  1.519149  0.073772    1.893773       0.487091  \n",
      "9   0.215873    0.666667  1.521739  0.074014    1.685714       0.507042  \n",
      "10  0.215873    0.809524  1.613924  0.082116    2.616667       0.518717  \n",
      "11  0.203175    0.627451  1.250931  0.040756    1.337845       0.296655  \n",
      "12  0.203175    0.666667  1.400000  0.058050    1.571429       0.410959  \n",
      "13  0.203175    0.831169  1.657077  0.080564    2.952137       0.524816  \n"
     ]
    }
   ],
   "source": [
    "rules_of_association = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "print(rules_of_association)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide explanation about __antecedent support__, __consequent support__, __support__, __confidence__, __lift__, __leverage__ and __conviction__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Support:\n",
    "\n",
    "-Formula: Support(A) = (Transactions containing A) / (Total transactions)\n",
    "\n",
    "-Support measures the proportion of transactions in the dataset that contain the itemset A. Higher support indicates that the itemset is more frequent in the dataset.\n",
    "\n",
    "2. Confidence:\n",
    "\n",
    "-Formula: Confidence(A → B) = Support(A ∩ B) / Support(A)\n",
    "\n",
    "-Confidence measures the likelihood that a transaction containing itemset A also contains itemset B. It is the conditional probability of B given A. Higher confidence indicates a stronger association between A and B.\n",
    "\n",
    "3. Lift:\n",
    "\n",
    "-Formula: Lift(A → B) = (Support(A ∩ B) / Support(A)) / Support(B)\n",
    "\n",
    "-Lift measures the ratio of the observed support to the expected support if A and B were independent. A lift value greater than 1 indicates that the presence of A has a positive effect on the presence of B. A lift value less than 1 suggests a negative effect, and a lift value close to 1 suggests independence.\n",
    "\n",
    "4. Leverage:\n",
    "\n",
    "-Formula: Leverage(A → B) = Support(A ∩ B) - Support(A) * Support(B)\n",
    "\n",
    "-Leverage measures the difference between the observed support of A and B together and the expected support if they were independent. A leverage value of 0 indicates independence, while positive values suggest a positive relationship.\n",
    "\n",
    "5. Conviction:\n",
    "\n",
    "-Formula: Conviction(A → B) = (1 - Support(B)) / (1 - Confidence(A → B))\n",
    "\n",
    "-Conviction measures the ratio of the expected frequency that A occurs without B to the observed frequency of A without B. Higher conviction values indicate stronger dependency between A and B, with values approaching infinity indicating a strong dependency.\n",
    "\n",
    "6. Antecedent Support:\n",
    "\n",
    "-The support of the antecedent (left-hand side) of the rule.\n",
    "\n",
    "-Formula: Support(A)\n",
    "\n",
    "-Antecedent support measures the proportion of transactions that contain the antecedent of the rule.\n",
    "\n",
    "7. Consequent Support:\n",
    "\n",
    "-The support of the consequent (right-hand side) of the rule.\n",
    "\n",
    "-Formula: Support(B)\n",
    "\n",
    "-Consequent support measures the proportion of transactions that contain the consequent of the rule."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
